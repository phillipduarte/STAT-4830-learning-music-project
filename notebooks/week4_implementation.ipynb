{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e451df52",
   "metadata": {},
   "source": [
    "# Music Feature Extraction and Deep Learning Model\n",
    "\n",
    "This notebook demonstrates feature extraction from sheet music using `music21` and a Siamese ResNet model for page matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88fc276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from music21 import corpus\n",
    "\n",
    "from features import MeasureFeatureExtractor, load_and_extract_features\n",
    "from model import create_model, SiamesePageMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928d6d37",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction\n",
    "\n",
    "First, let's extract features from a Bach chorale using our `MeasureFeatureExtractor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73af30f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 25\n",
      "Extracted features shape: (17, 25)\n",
      "Number of measures: 17\n",
      "Features per measure: 25\n"
     ]
    }
   ],
   "source": [
    "# Load a sample score from the music21 corpus\n",
    "score = corpus.parse('bach/bwv65.2.xml')\n",
    "\n",
    "# Create feature extractor\n",
    "extractor = MeasureFeatureExtractor()\n",
    "\n",
    "# Extract features from the score\n",
    "features = extractor.extract_from_score(score)\n",
    "\n",
    "print(f\"Extracted features shape: {features.shape}\")\n",
    "print(f\"Number of measures: {features.shape[0]}\")\n",
    "print(f\"Features per measure: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b243907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature names:\n",
      "   0. mean_pitch\n",
      "   1. pitch_range\n",
      "   2. pitch_std\n",
      "   3. min_pitch\n",
      "   4. max_pitch\n",
      "   5. pc_C\n",
      "   6. pc_C#\n",
      "   7. pc_D\n",
      "   8. pc_D#\n",
      "   9. pc_E\n",
      "  10. pc_F\n",
      "  11. pc_F#\n",
      "  12. pc_G\n",
      "  13. pc_G#\n",
      "  14. pc_A\n",
      "  15. pc_A#\n",
      "  16. pc_B\n",
      "  17. note_density\n",
      "  18. mean_duration\n",
      "  19. duration_std\n",
      "  20. min_duration\n",
      "  21. max_duration\n",
      "  22. key_signature\n",
      "  23. time_sig_numerator\n",
      "  24. time_sig_denominator\n"
     ]
    }
   ],
   "source": [
    "# Display feature names\n",
    "feature_names = extractor.get_feature_names()\n",
    "print(\"\\nFeature names:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i:2d}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ef40424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First measure features:\n",
      "  mean_pitch               : 69.000\n",
      "  pitch_range              : 0.000\n",
      "  pitch_std                : 0.000\n",
      "  min_pitch                : 69.000\n",
      "  max_pitch                : 69.000\n",
      "  pc_C                     : 0.000\n",
      "  pc_C#                    : 0.000\n",
      "  pc_D                     : 0.000\n",
      "  pc_D#                    : 0.000\n",
      "  pc_E                     : 0.000\n",
      "  pc_F                     : 0.000\n",
      "  pc_F#                    : 0.000\n",
      "  pc_G                     : 0.000\n",
      "  pc_G#                    : 0.000\n",
      "  pc_A                     : 1.000\n",
      "  pc_A#                    : 0.000\n",
      "  pc_B                     : 0.000\n",
      "  note_density             : 1.000\n",
      "  mean_duration            : 1.000\n",
      "  duration_std             : 0.000\n",
      "  min_duration             : 1.000\n",
      "  max_duration             : 1.000\n",
      "  key_signature            : 0.000\n",
      "  time_sig_numerator       : 3.000\n",
      "  time_sig_denominator     : 4.000\n"
     ]
    }
   ],
   "source": [
    "# Show features for the first measure\n",
    "print(\"\\nFirst measure features:\")\n",
    "for name, value in zip(feature_names, features[0]):\n",
    "    print(f\"  {name:25s}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c95b54",
   "metadata": {},
   "source": [
    "## 2. Deep Learning Model\n",
    "\n",
    "Now let's create and test the Siamese ResNet model for page matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "456c9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with 3,920,320 parameters\n"
     ]
    }
   ],
   "source": [
    "# Create model configuration\n",
    "config = {\n",
    "    'feature_dim': 25,\n",
    "    'embedding_dim': 128,\n",
    "    'num_blocks_per_stage': (2, 2, 2, 2),  # ResNet-18 style\n",
    "    'base_channels': 64,\n",
    "    'similarity_metric': 'cosine'\n",
    "}\n",
    "\n",
    "# Initialize model\n",
    "model = create_model(config)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model created with {num_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de41c8",
   "metadata": {},
   "source": [
    "### Test the model with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9db4f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page tensor shape: torch.Size([1, 32, 25])\n",
      "Page tensor dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Convert features to PyTorch tensor\n",
    "# Add batch dimension and ensure we have 32 measures (pad if necessary)\n",
    "target_measures = 32\n",
    "current_measures = features.shape[0]\n",
    "\n",
    "if current_measures < target_measures:\n",
    "    # Pad with zeros\n",
    "    padding = np.zeros((target_measures - current_measures, features.shape[1]), dtype=np.float32)\n",
    "    features_padded = np.vstack([features, padding])\n",
    "else:\n",
    "    # Take first 32 measures\n",
    "    features_padded = features[:target_measures]\n",
    "\n",
    "# Convert to tensor and add batch dimension (ensure float32)\n",
    "page_tensor = torch.from_numpy(features_padded).float().unsqueeze(0)\n",
    "print(f\"Page tensor shape: {page_tensor.shape}\")  # Should be (1, 32, 25)\n",
    "print(f\"Page tensor dtype: {page_tensor.dtype}\")  # Should be torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14c90ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: torch.Size([1, 128])\n",
      "Embedding norm: 76.741\n"
     ]
    }
   ],
   "source": [
    "# Get embedding for the page\n",
    "model.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    embedding = model.get_embeddings(page_tensor)\n",
    "    print(f\"Embedding shape: {embedding.shape}\")  # Should be (1, 128)\n",
    "    print(f\"Embedding norm: {torch.norm(embedding).item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4bb31e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of page with itself: 1.0000\n",
      "Similarity with random page: 0.9599\n"
     ]
    }
   ],
   "source": [
    "# Test similarity between the page and itself (should be ~1.0)\n",
    "with torch.no_grad():\n",
    "    similarity = model(page_tensor, page_tensor)\n",
    "    print(f\"Similarity of page with itself: {similarity.item():.4f}\")\n",
    "    \n",
    "# Test with a different random page (should be lower)\n",
    "random_page = torch.randn(1, 32, 25)\n",
    "with torch.no_grad():\n",
    "    similarity_random = model(page_tensor, random_page)\n",
    "    print(f\"Similarity with random page: {similarity_random.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bacffa9",
   "metadata": {},
   "source": [
    "## 3. Compare Multiple Bach Chorales\n",
    "\n",
    "Let's extract features from multiple pieces and compare their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4a087c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed bwv65.2.xml\n",
      "Processed bwv66.6.xml\n",
      "Processed bwv69.6.xml\n"
     ]
    }
   ],
   "source": [
    "# Load several Bach chorales\n",
    "bach_pieces = [\n",
    "    'bach/bwv65.2.xml',\n",
    "    'bach/bwv66.6.xml',\n",
    "    'bach/bwv69.6.xml'\n",
    "]\n",
    "\n",
    "embeddings_list = []\n",
    "piece_names = []\n",
    "\n",
    "for piece in bach_pieces:\n",
    "    score = corpus.parse(piece)\n",
    "    feats = extractor.extract_from_score(score, max_measures=32)\n",
    "    \n",
    "    # Pad if necessary\n",
    "    if feats.shape[0] < 32:\n",
    "        padding = np.zeros((32 - feats.shape[0], feats.shape[1]), dtype=np.float32)\n",
    "        feats = np.vstack([feats, padding])\n",
    "    else:\n",
    "        feats = feats[:32]\n",
    "    \n",
    "    # Convert to tensor (ensure float32)\n",
    "    page_tensor = torch.from_numpy(feats).float().unsqueeze(0)\n",
    "    \n",
    "    # Get embedding\n",
    "    with torch.no_grad():\n",
    "        emb = model.get_embeddings(page_tensor)\n",
    "        embeddings_list.append(emb)\n",
    "    \n",
    "    piece_names.append(piece.split('/')[-1])\n",
    "    print(f\"Processed {piece_names[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38ee3092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pairwise similarities:\n",
      "  bwv65.2.xml <-> bwv65.2.xml: 1.0000\n",
      "  bwv65.2.xml <-> bwv66.6.xml: 0.9684\n",
      "  bwv65.2.xml <-> bwv69.6.xml: 0.9762\n",
      "  bwv66.6.xml <-> bwv66.6.xml: 1.0000\n",
      "  bwv66.6.xml <-> bwv69.6.xml: 0.9507\n",
      "  bwv69.6.xml <-> bwv69.6.xml: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Compute pairwise similarities\n",
    "print(\"\\nPairwise similarities:\")\n",
    "for i in range(len(embeddings_list)):\n",
    "    for j in range(i, len(embeddings_list)):\n",
    "        emb1 = embeddings_list[i]\n",
    "        emb2 = embeddings_list[j]\n",
    "        \n",
    "        similarity = torch.nn.functional.cosine_similarity(emb1, emb2, dim=1)\n",
    "        similarity = (similarity + 1) / 2  # Map to [0, 1]\n",
    "        \n",
    "        print(f\"  {piece_names[i]} <-> {piece_names[j]}: {similarity.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09931ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f18a031",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "\n",
    "To train the model, we need to create a dataset of page pairs with labels indicating whether they match or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3077b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "\n",
    "class PagePairDataset(Dataset):\n",
    "    \"\"\"Dataset of page pairs for training.\"\"\"\n",
    "    \n",
    "    def __init__(self, scores, extractor, num_pairs=1000, target_measures=16, overlap=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            scores: List of music21 scores\n",
    "            extractor: MeasureFeatureExtractor instance\n",
    "            num_pairs: Number of training pairs to generate\n",
    "            target_measures: Number of measures per page\n",
    "            overlap: Number of measures to overlap between pages (for sliding window)\n",
    "        \"\"\"\n",
    "        self.num_pairs = num_pairs\n",
    "        self.target_measures = target_measures\n",
    "        \n",
    "        # Pre-extract multiple pages from each score using sliding window\n",
    "        self.pages_by_piece = []  # List of lists: each inner list contains pages from one piece\n",
    "        \n",
    "        for score in scores:\n",
    "            # Extract all features from the score\n",
    "            all_feats = extractor.extract_from_score(score)\n",
    "            \n",
    "            # Create multiple pages using sliding window\n",
    "            pages_from_this_piece = []\n",
    "            stride = target_measures - overlap  # How much to shift the window\n",
    "            \n",
    "            for start_idx in range(0, all_feats.shape[0], stride):\n",
    "                end_idx = start_idx + target_measures\n",
    "                \n",
    "                # Extract page\n",
    "                if end_idx <= all_feats.shape[0]:\n",
    "                    page = all_feats[start_idx:end_idx]\n",
    "                else:\n",
    "                    # Last page - pad if necessary\n",
    "                    page = all_feats[start_idx:]\n",
    "                    if page.shape[0] < target_measures:\n",
    "                        padding = np.zeros((target_measures - page.shape[0], all_feats.shape[1]), dtype=np.float32)\n",
    "                        page = np.vstack([page, padding])\n",
    "                \n",
    "                pages_from_this_piece.append(page)\n",
    "            \n",
    "            # Only add pieces that have at least 2 pages (so we can make positive pairs)\n",
    "            if len(pages_from_this_piece) >= 2:\n",
    "                self.pages_by_piece.append(pages_from_this_piece)\n",
    "        \n",
    "        if len(self.pages_by_piece) < 2:\n",
    "            raise ValueError(f\"Need at least 2 pieces with multiple pages, but only found {len(self.pages_by_piece)}. \"\n",
    "                           f\"Try using longer pieces or reducing target_measures.\")\n",
    "        \n",
    "        print(f\"Loaded {len(self.pages_by_piece)} pieces with multiple pages\")\n",
    "        for i, pages in enumerate(self.pages_by_piece):\n",
    "            print(f\"  Piece {i}: {len(pages)} pages\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_pairs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Generate positive pair (same piece, different pages) or negative pair (different pieces)\n",
    "        is_match = random.random() > 0.5\n",
    "        \n",
    "        if is_match:\n",
    "            # Positive pair: different pages from the same piece\n",
    "            piece_idx = random.randint(0, len(self.pages_by_piece) - 1)\n",
    "            pages = self.pages_by_piece[piece_idx]\n",
    "            \n",
    "            # Select two different pages from this piece\n",
    "            page_idx1, page_idx2 = random.sample(range(len(pages)), 2)\n",
    "            page1 = pages[page_idx1]\n",
    "            page2 = pages[page_idx2]\n",
    "            label = 1.0\n",
    "        else:\n",
    "            # Negative pair: pages from different pieces\n",
    "            piece_idx1, piece_idx2 = random.sample(range(len(self.pages_by_piece)), 2)\n",
    "            \n",
    "            page1 = random.choice(self.pages_by_piece[piece_idx1])\n",
    "            page2 = random.choice(self.pages_by_piece[piece_idx2])\n",
    "            label = 0.0\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(page1).float(),\n",
    "            torch.from_numpy(page2).float(),\n",
    "            torch.tensor(label, dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7726608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "  Loaded bach/bwv65.2.xml\n",
      "  Loaded bach/bwv66.6.xml\n",
      "  Loaded bach/bwv69.6.xml\n",
      "  Loaded bach/bwv4.8.xml\n",
      "  Loaded bach/bwv5.7.xml\n",
      "  Loaded bach/bwv6.6.xml\n",
      "  Loaded bach/bwv7.7.xml\n",
      "  Loaded bach/bwv10.7.xml\n",
      "\n",
      "Loaded 8 pieces for training\n"
     ]
    }
   ],
   "source": [
    "# Load multiple Bach chorales for training\n",
    "print(\"Loading training data...\")\n",
    "train_pieces = [\n",
    "    'bach/bwv65.2.xml',\n",
    "    'bach/bwv66.6.xml',\n",
    "    'bach/bwv69.6.xml',\n",
    "    'bach/bwv4.8.xml',\n",
    "    'bach/bwv5.7.xml',\n",
    "    'bach/bwv6.6.xml',\n",
    "    'bach/bwv7.7.xml',\n",
    "    'bach/bwv10.7.xml'\n",
    "]\n",
    "\n",
    "train_scores = []\n",
    "for piece in train_pieces:\n",
    "    try:\n",
    "        score = corpus.parse(piece)\n",
    "        train_scores.append(score)\n",
    "        print(f\"  Loaded {piece}\")\n",
    "    except:\n",
    "        print(f\"  Failed to load {piece}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(train_scores)} pieces for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "240cdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4 pieces with multiple pages\n",
      "  Piece 0: 2 pages\n",
      "  Piece 1: 2 pages\n",
      "  Piece 2: 2 pages\n",
      "  Piece 3: 2 pages\n",
      "Training dataset size: 200 pairs\n",
      "Number of batches: 25\n"
     ]
    }
   ],
   "source": [
    "# Create dataset and dataloader\n",
    "train_dataset = PagePairDataset(train_scores, extractor, num_pairs=200, target_measures=16)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "print(f\"Training dataset size: {len(train_dataset)} pairs\")\n",
    "print(f\"Number of batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49c8e6",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645297ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch [1/10] - Loss: 0.5759, Accuracy: 69.50%\n",
      "Epoch [2/10] - Loss: 0.2733, Accuracy: 91.00%\n",
      "Epoch [3/10] - Loss: 0.3389, Accuracy: 86.00%\n",
      "Epoch [4/10] - Loss: 0.2704, Accuracy: 92.00%\n",
      "Epoch [5/10] - Loss: 0.2761, Accuracy: 90.50%\n",
      "Epoch [6/10] - Loss: 0.2683, Accuracy: 90.00%\n",
      "Epoch [7/10] - Loss: 0.2601, Accuracy: 91.00%\n",
      "Epoch [8/10] - Loss: 0.2916, Accuracy: 92.00%\n",
      "Epoch [9/10] - Loss: 0.2915, Accuracy: 93.50%\n",
      "Epoch [10/10] - Loss: 0.2810, Accuracy: 91.00%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "model.train()  # Set to training mode\n",
    "criterion = torch.nn.BCELoss()  # Binary cross-entropy loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (page1, page2, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        similarity = model(page1, page2)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(similarity, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        total_loss += loss.item()\n",
    "        predictions = (similarity > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123cf6b",
   "metadata": {},
   "source": [
    "## 5. Testing the Trained Model\n",
    "\n",
    "Now let's test the model on new pieces it hasn't seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd78cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n",
      "  Loaded bach/bwv11.6.xml\n",
      "  Loaded bach/bwv12.7.xml\n",
      "  Loaded bach/bwv13.6.xml\n",
      "  Loaded bach/bwv14.5.xml\n",
      "\n",
      "Loaded 4 pieces for testing\n"
     ]
    }
   ],
   "source": [
    "# Load test pieces (different from training)\n",
    "print(\"Loading test data...\")\n",
    "test_pieces = [\n",
    "    'bach/bwv11.6.xml',\n",
    "    'bach/bwv12.7.xml',\n",
    "    'bach/bwv13.6.xml',\n",
    "    'bach/bwv14.5.xml'\n",
    "]\n",
    "\n",
    "test_scores = []\n",
    "for piece in test_pieces:\n",
    "    try:\n",
    "        score = corpus.parse(piece)\n",
    "        test_scores.append(score)\n",
    "        print(f\"  Loaded {piece}\")\n",
    "    except:\n",
    "        print(f\"  Failed to load {piece}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(test_scores)} pieces for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "96057219",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Need at least 2 pieces with multiple pages, but only found 1. Try using longer pieces or reducing target_measures.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create test dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_dataset = \u001b[43mPagePairDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pairs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m8\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTest dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m pairs\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mPagePairDataset.__init__\u001b[39m\u001b[34m(self, scores, extractor, num_pairs, target_measures, overlap)\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[38;5;28mself\u001b[39m.pages_by_piece.append(pages_from_this_piece)\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.pages_by_piece) < \u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNeed at least 2 pieces with multiple pages, but only found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.pages_by_piece)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     52\u001b[39m                    \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTry using longer pieces or reducing target_measures.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.pages_by_piece)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m pieces with multiple pages\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, pages \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.pages_by_piece):\n",
      "\u001b[31mValueError\u001b[39m: Need at least 2 pieces with multiple pages, but only found 1. Try using longer pieces or reducing target_measures."
     ]
    }
   ],
   "source": [
    "# Create test dataset\n",
    "test_dataset = PagePairDataset(test_scores, extractor, num_pairs=100)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"Test dataset size: {len(test_dataset)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8045749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEvaluating model on test set...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Forward pass\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43msimilarity\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Compute loss\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phill\\Documents\\STAT-4830-learning-music-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phill\\Documents\\STAT-4830-learning-music-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:801\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    799\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    800\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m801\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    803\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\phill\\Documents\\STAT-4830-learning-music-project\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     52\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     56\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mPagePairDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     70\u001b[39m     label = \u001b[32m1.0\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Negative pair: pages from different pieces\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     piece_idx1, piece_idx2 = \u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpages_by_piece\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     page1 = random.choice(\u001b[38;5;28mself\u001b[39m.pages_by_piece[piece_idx1])\n\u001b[32m     76\u001b[39m     page2 = random.choice(\u001b[38;5;28mself\u001b[39m.pages_by_piece[piece_idx2])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python313\\Lib\\random.py:434\u001b[39m, in \u001b[36mRandom.sample\u001b[39m\u001b[34m(self, population, k, counts)\u001b[39m\n\u001b[32m    432\u001b[39m randbelow = \u001b[38;5;28mself\u001b[39m._randbelow\n\u001b[32m    433\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m0\u001b[39m <= k <= n:\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSample larger than population or is negative\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    435\u001b[39m result = [\u001b[38;5;28;01mNone\u001b[39;00m] * k\n\u001b[32m    436\u001b[39m setsize = \u001b[32m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "model.eval()  # Set to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "true_negatives = 0\n",
    "false_negatives = 0\n",
    "\n",
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for page1, page2, labels in test_loader:\n",
    "        # Forward pass\n",
    "        similarity = model(page1, page2)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(similarity, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Predictions\n",
    "        predictions = (similarity > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Confusion matrix\n",
    "        for pred, label in zip(predictions, labels):\n",
    "            if pred == 1 and label == 1:\n",
    "                true_positives += 1\n",
    "            elif pred == 1 and label == 0:\n",
    "                false_positives += 1\n",
    "            elif pred == 0 and label == 0:\n",
    "                true_negatives += 1\n",
    "            elif pred == 0 and label == 1:\n",
    "                false_negatives += 1\n",
    "\n",
    "# Print results\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall: {recall:.4f}\")\n",
    "print(f\"  F1 Score: {f1:.4f}\")\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"  True Positives: {true_positives}\")\n",
    "print(f\"  False Positives: {false_positives}\")\n",
    "print(f\"  True Negatives: {true_negatives}\")\n",
    "print(f\"  False Negatives: {false_negatives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f97f4b",
   "metadata": {},
   "source": [
    "### Visualize Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f69a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing specific piece comparisons:\n",
      "\n",
      "[SAME] bwv11.6.xml <-> bwv11.6.xml: 1.0000\n",
      "[DIFF] bwv11.6.xml <-> bwv12.7.xml: 0.3361\n",
      "[DIFF] bwv11.6.xml <-> bwv13.6.xml: 0.3294\n",
      "[DIFF] bwv11.6.xml <-> bwv14.5.xml: 0.2468\n",
      "[SAME] bwv12.7.xml <-> bwv12.7.xml: 1.0000\n",
      "[DIFF] bwv12.7.xml <-> bwv13.6.xml: 0.9994\n",
      "[DIFF] bwv12.7.xml <-> bwv14.5.xml: 0.2937\n",
      "[SAME] bwv13.6.xml <-> bwv13.6.xml: 1.0000\n",
      "[DIFF] bwv13.6.xml <-> bwv14.5.xml: 0.3048\n",
      "[SAME] bwv14.5.xml <-> bwv14.5.xml: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Test with specific examples\n",
    "print(\"Testing specific piece comparisons:\\n\")\n",
    "\n",
    "test_features = []\n",
    "for i, score in enumerate(test_scores):\n",
    "    feats = extractor.extract_from_score(score, max_measures=32)\n",
    "    if feats.shape[0] < 32:\n",
    "        padding = np.zeros((32 - feats.shape[0], feats.shape[1]), dtype=np.float32)\n",
    "        feats = np.vstack([feats, padding])\n",
    "    else:\n",
    "        feats = feats[:32]\n",
    "    test_features.append(feats)\n",
    "\n",
    "# Compare all pairs\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_features)):\n",
    "        for j in range(i, len(test_features)):\n",
    "            page1 = torch.from_numpy(test_features[i]).float().unsqueeze(0)\n",
    "            page2 = torch.from_numpy(test_features[j]).float().unsqueeze(0)\n",
    "            \n",
    "            similarity = model(page1, page2).item()\n",
    "            \n",
    "            piece1 = test_pieces[i].split('/')[-1]\n",
    "            piece2 = test_pieces[j].split('/')[-1]\n",
    "            \n",
    "            match_type = \"SAME\" if i == j else \"DIFF\"\n",
    "            print(f\"[{match_type}] {piece1} <-> {piece2}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f98c66",
   "metadata": {},
   "source": [
    "## 6. Save and Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38d56c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/page_matcher.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_path = '../models/page_matcher.pth'\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': config,\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a00a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Test output shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Load the model (example)\n",
    "checkpoint = torch.load(model_path)\n",
    "\n",
    "# Create new model instance\n",
    "loaded_model = create_model(checkpoint['config'])\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test that it works\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 32, 25)\n",
    "    output = loaded_model.get_embeddings(test_input)\n",
    "    print(f\"Test output shape: {output.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
